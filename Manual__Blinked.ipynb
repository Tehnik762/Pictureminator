{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938bbd1b",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebooks creates model from images with blinked eyes\n",
    "It will choose the best model to use with them and then eliminate some features to get the better result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fbf45",
   "metadata": {},
   "source": [
    "### Import DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5fd0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "import multiprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d9135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9847b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "screenshots = pd.read_csv(\"./images/screenshots/screenshots.csv\")\n",
    "\n",
    "screenshots_ph = pd.read_csv(\"./images/screenshots_ph/screenshots_ph.csv\")\n",
    "\n",
    "regulars = pd.read_csv(\"./images/regular/regular.csv\")\n",
    "\n",
    "not_good = pd.read_csv(\"./images/not_good/not_good.csv\")\n",
    "\n",
    "superb = pd.read_csv(\"./images/superb/superb.csv\")\n",
    "\n",
    "docs = pd.read_csv(\"./images/docs/docs.csv\")\n",
    "\n",
    "blinked = pd.read_csv(\"./images/blinked/blinked.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./images/test/test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0a0cb",
   "metadata": {},
   "source": [
    "### Labeling and spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4929669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_labels = [\"blinked\", \"docs\", \"not_good\", \"receipts\", \"regular\", \"screenshots\", \"screenshots_ph\", \"superb\", \"test\"]\n",
    "\n",
    "label = \"blinked\"\n",
    "\n",
    "blinked[label] = 1\n",
    "regulars[label] = 0\n",
    "not_good[label] = 0\n",
    "superb[label] = 0\n",
    "screenshots[label] = 0\n",
    "docs[label] = 0\n",
    "screenshots_ph[label] = 0\n",
    "\n",
    "whole_docs = pd.concat([blinked, regulars, not_good, superb, screenshots, docs, screenshots_ph], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4001918",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_docs = whole_docs.drop(columns=[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baab0d3-5b9a-468b-ac33-93cc4c12d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_docs = whole_docs.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca4897f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = whole_docs.pop(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5c4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(whole_docs, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1195777",
   "metadata": {},
   "source": [
    "## Running on 4 Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b148b",
   "metadata": {},
   "source": [
    "### ExtraTree simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d951f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers_3 as c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12d21ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Usage of 3classifiers.py:\n",
      "        from 3classifiers import extratrees_model\n",
      "    Usage example:\n",
      "        best_model = extratrees_model(X_train, y_train, param_grid)\n",
      "\n",
      "   Predefined examples:          \n",
      "          param_extratrees = {'n_estimators': range(100, 400, 50), 'min_samples_split': range(2, 19, 2), 'min_samples_leaf': range(1, 13, 2)}\n",
      "    \n",
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n",
      "Time taken to train the model: 5 minutes and 34.65 seconds\n",
      "Best parameters: {'extratreesclassifier__min_samples_leaf': 1, 'extratreesclassifier__min_samples_split': 2, 'extratreesclassifier__n_estimators': 100}\n",
      "Best score: 0.9742063492063492\n"
     ]
    }
   ],
   "source": [
    "search_scr = c3.extratrees_model(X_train, y_train, c3.param_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6b10c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c56070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Usage of 3classifiers.py:\n",
      "        from 3classifiers import catboost_model\n",
      "    Usage example:\n",
      "        best_model = catboost_model(X_train, y_train, param_grid)\n",
      "\n",
      "   Predefined examples:          \n",
      "          param_catboost = {'iterations': range(100, 400, 50), 'depth': range(4, 10, 2), 'l2_leaf_reg': array([1.00000000e-20, 3.16227766e-20, 1.00000000e-19])}\n",
      "    \n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "10 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\catboost\\core.py\", line 5100, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\catboost\\core.py\", line 2319, in _fit\n",
      "    self._train(\n",
      "  File \"C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\catboost\\core.py\", line 1723, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4645, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4694, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Anaconda\\envs\\pictureminator\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.98373016 0.98492063 0.98492063 0.98492063\n",
      " 0.98452381 0.98452381 0.98452381 0.98571429 0.98571429 0.98571429\n",
      " 0.98531746 0.98531746 0.98531746 0.98650794 0.98650794 0.98650794\n",
      " 0.98174603 0.98174603 0.98174603 0.98253968 0.98253968 0.98253968\n",
      " 0.98293651 0.98293651 0.98293651 0.98293651 0.98293651 0.98293651\n",
      " 0.98373016 0.98373016 0.98373016 0.98373016 0.98373016 0.98373016\n",
      " 0.97896825 0.97896825 0.97896825 0.97936508 0.97936508 0.97936508\n",
      " 0.97936508 0.97936508 0.97936508 0.97936508 0.97936508 0.97936508\n",
      " 0.97936508 0.97936508 0.97936508 0.97936508 0.97936508 0.97936508]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: 25 minutes and 58.30 seconds\n",
      "Best parameters: {'catboostclassifier__depth': 4, 'catboostclassifier__iterations': 350, 'catboostclassifier__l2_leaf_reg': 1e-20}\n",
      "Best score: 0.9865079365079363\n"
     ]
    }
   ],
   "source": [
    "search_cb = c3.catboost_model(X_train, y_train, c3.param_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8e7d2",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7930e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Usage of 3classifiers.py:\n",
      "        from 3classifiers import lgbm_model\n",
      "    Usage example:\n",
      "        best_model = lgbm_model(X_train, y_train, param_grid)\n",
      "\n",
      "   Predefined examples:          \n",
      "          param_lgbm = {'n_estimators': range(100, 400, 50), 'num_leaves': range(20, 40, 5), 'min_child_samples': range(1, 20, 2)}\n",
      "    \n",
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "[LightGBM] [Info] Number of positive: 73, number of negative: 2447\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21764\n",
      "[LightGBM] [Info] Number of data points in the train set: 2520, number of used features: 94\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028968 -> initscore=-3.512159\n",
      "[LightGBM] [Info] Start training from score -3.512159\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Time taken to train the model: 14 minutes and 9.20 seconds\n",
      "Best parameters: {'lgbmclassifier__min_child_samples': 1, 'lgbmclassifier__n_estimators': 100, 'lgbmclassifier__num_leaves': 20}\n",
      "Best score: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "param_lgbm = {\n",
    "        'n_estimators': range(100, 400, 50), \n",
    "        'num_leaves': range(20, 40, 5), \n",
    "        'min_child_samples': range(1, 20, 2)\n",
    "}\n",
    "\n",
    "search_lgbm = c3.lgbm_model(X_train, y_train, c3.param_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17cf133",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7e3ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Usage of 3classifiers.py:\n",
      "        from 3classifiers import adaboost_model\n",
      "    Usage example:\n",
      "        best_model = adaboost_model(X_train, y_train, param_grid)\n",
      "\n",
      "   Predefined examples:          \n",
      "          param_adaboost = {'n_estimators': range(50, 400, 50), 'learning_rate': [0.01, 0.1, 1.0], 'estimator__max_depth': [1, 2, 3]}\n",
      "    \n",
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n",
      "Time taken to train the model: 20 minutes and 9.83 seconds\n",
      "Best parameters: {'adaboostclassifier__estimator__max_depth': 1, 'adaboostclassifier__learning_rate': 1.0, 'adaboostclassifier__n_estimators': 100}\n",
      "Best score: 0.9880952380952379\n"
     ]
    }
   ],
   "source": [
    "param_adaboost = {\n",
    "        'n_estimators': range(50, 400, 50), \n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "search_ab = c3.adaboost_model(X_train, y_train, c3.param_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328128e",
   "metadata": {},
   "source": [
    "### All 4 classifiers comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a0f8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier     Best Score - blinked\n",
      "ExtraTrees     0.9742\n",
      "LightGBM       0.9889\n",
      "CatBoost       0.9865\n",
      "AdaBoost       0.9881\n"
     ]
    }
   ],
   "source": [
    "best_score_et = search_scr.best_score_\n",
    "best_score_lgbm = search_lgbm.best_score_\n",
    "best_score_catboost = search_cb.best_score_\n",
    "best_score_adaboost = search_ab.best_score_\n",
    "\n",
    "# Create a list to display the results\n",
    "results = [\n",
    "    ('ExtraTrees', best_score_et),\n",
    "    ('LightGBM', best_score_lgbm),\n",
    "    ('CatBoost', best_score_catboost),\n",
    "    ('AdaBoost', best_score_adaboost)\n",
    "]\n",
    "\n",
    "# Print the results in a tabular format\n",
    "print(f\"{'Classifier':<15}{f'Best Score - {label}'}\")\n",
    "for name, score in results:\n",
    "    print(f\"{name:<15}{score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dedf87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [search_scr, search_lgbm, \n",
    "           search_cb, search_ab]\n",
    "\n",
    "results_with_identifiers = [\n",
    "    (search_scr, 'scr'),\n",
    "    (search_lgbm, 'lgbm'),\n",
    "    (search_cb, 'cb'),\n",
    "    (search_ab, 'ab')\n",
    "]\n",
    "\n",
    "classifier_mapping = {\n",
    "    'scr': 'ExtraTrees',\n",
    "    'lgbm': 'LightGBM',\n",
    "    'cb': 'CatBoost',\n",
    "    'ab': 'AdaBoost'\n",
    "}\n",
    "\n",
    "named_steps_estimator = {\n",
    "    'scr': 'extratreesclassifier',\n",
    "    'lgbm': 'lgbmclassifier',\n",
    "    'cb': 'catboostclassifier',\n",
    "    'ab': 'adaboostclassifier'\n",
    "}\n",
    "\n",
    "best_model, best_identifier = results_with_identifiers[0]\n",
    "\n",
    "for model, identifier in results_with_identifiers[1:]:\n",
    "    if model.best_score_ > best_model.best_score_:\n",
    "        best_model = model\n",
    "        best_identifier = identifier\n",
    "\n",
    "# Use best_identifier to get the classifier name from the mapping\n",
    "classifier_name = classifier_mapping.get(best_identifier, 'Unknown')\n",
    "nsteps = named_steps_estimator.get(best_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cbcb9",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ace901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blinked'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = test.pop(\"filename\")\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ebba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not true</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  prediction\n",
       "metric                        \n",
       "FN               4           4\n",
       "not true        89          89\n",
       "true             1           1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = best_model.predict(test)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['filename'] = filenames\n",
    "result['prediction'] = prediction\n",
    "\n",
    "result.loc[(result.prediction == 1) & (result.filename.str.contains(label)), \"metric\"] = \"true\"\n",
    "result.loc[(result.prediction == 0) & (result.filename.str.contains(label)), \"metric\"] = \"FN\"\n",
    "result.loc[(result.prediction == 0) & (~result.filename.str.contains(label)), \"metric\"] = \"not true\"\n",
    "result.loc[(result.prediction == 1) & (~result.filename.str.contains(label)), \"metric\"] = \"FP\"\n",
    "\n",
    "result.groupby(\"metric\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16f25893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, prediction, metric]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result.metric == \"FP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b07627",
   "metadata": {},
   "source": [
    "#### Confusion matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8c775d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListedColormap, BoundaryNorm\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define your color boundaries and corresponding colors\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define your color boundaries and corresponding colors\n",
    "boundaries = [0, 5, 10, 20, 50, 60, 70, 100]  # Assuming 80 is your max value\n",
    "colors = [\n",
    "    'darkgreen',  # 0-5\n",
    "    'green',      # 5-10\n",
    "    '#ffcccc',    # 10-20 (light red)\n",
    "    'red',        # 20-50\n",
    "    'lightblue',  # 50-60\n",
    "    'blue',       # 60-70\n",
    "    'darkblue'    # above 70\n",
    "]\n",
    "\n",
    "# Create a colormap\n",
    "custom_cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(boundaries, custom_cmap.N, clip=True)\n",
    "\n",
    "\n",
    "tp = sum(result['metric'] == 'true')  \n",
    "fn = sum(result['metric'] == 'FN')    \n",
    "tn = sum(result['metric'] == 'not true')  \n",
    "fp = sum(result['metric'] == 'FP') \n",
    "\n",
    "conf_matrix = np.array([[tp, fn],\n",
    "                        [fp, tn]])\n",
    "\n",
    "# You can then plot this using seaborn or matplotlib\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_cmap, norm=norm, \n",
    "            xticklabels=['Positive', 'Negative'], \n",
    "            yticklabels=['Positive', 'Negative'])\n",
    "plt.ylabel('Actual Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb04f08",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a1062-339c-42ab-94e6-861718b32b5f",
   "metadata": {},
   "source": [
    "## Eliminating  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9244c-ff68-4894-81de-cb70e924f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65101b-092e-488d-8731-88c8f7f69fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_RFE = RFECV(best_estimator.named_steps[nsteps], cv=10, scoring=\"accuracy\", n_jobs = multiprocessing.cpu_count() - 1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe93a5-8d66-4148-ad64-e9f9c4ef7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "search_RFE.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa89ac-e780-45c4-bdad-e9dbba133426",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = search_RFE.predict(test)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['filename'] = filenames\n",
    "result['prediction'] = prediction\n",
    "\n",
    "result.loc[(result.prediction == 1) & (result.filename.str.contains(label)), \"metric\"] = \"true\"\n",
    "result.loc[(result.prediction == 0) & (result.filename.str.contains(label)), \"metric\"] = \"FN\"\n",
    "result.loc[(result.prediction == 0) & (~result.filename.str.contains(label)), \"metric\"] = \"not true\"\n",
    "result.loc[(result.prediction == 1) & (~result.filename.str.contains(label)), \"metric\"] = \"FP\"\n",
    "\n",
    "result.groupby(\"metric\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce758624-b995-4121-b965-050c73b065f8",
   "metadata": {},
   "source": [
    "# Confusion Matrix after eliminating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01708e16-3444-4d11-87a7-b672979053b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [0, 5, 10, 20, 50, 60, 70, 100]  # Assuming 80 is your max value\n",
    "colors = [\n",
    "    'darkgreen',  # 0-5\n",
    "    'green',      # 5-10\n",
    "    '#ffcccc',    # 10-20 (light red)\n",
    "    'red',        # 20-50\n",
    "    'lightblue',  # 50-60\n",
    "    'blue',       # 60-70\n",
    "    'darkblue'    # above 70\n",
    "]\n",
    "\n",
    "# Create a colormap\n",
    "custom_cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(boundaries, custom_cmap.N, clip=True)\n",
    "\n",
    "\n",
    "tp = sum(result['metric'] == 'true')  \n",
    "fn = sum(result['metric'] == 'FN')    \n",
    "tn = sum(result['metric'] == 'not true')  \n",
    "fp = sum(result['metric'] == 'FP') \n",
    "\n",
    "conf_matrix = np.array([[tp, fn],\n",
    "                        [fp, tn]])\n",
    "\n",
    "# You can then plot this using seaborn or matplotlib\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_cmap, norm=norm, \n",
    "            xticklabels=['Positive', 'Negative'], \n",
    "            yticklabels=['Positive', 'Negative'])\n",
    "plt.ylabel('Actual Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bfccd2-3c0b-44a8-bf1a-f0a676bf27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b5538-59d6-42a1-ab6f-812acd948ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_estimator = best_model.best_estimator_\n",
    "search_RFE = RFECV(best_estimator.named_steps[nsteps], cv=10, scoring=\"accuracy\", n_jobs = multiprocessing.cpu_count() - 1, verbose=3)\n",
    "search_RFE.fit(X_train, y_train)\n",
    "prediction = search_RFE.predict(test)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['filename'] = filenames\n",
    "result['prediction'] = prediction\n",
    "\n",
    "result.loc[(result.prediction == 1) & (result.filename.str.contains(label)), \"metric\"] = \"true\"\n",
    "result.loc[(result.prediction == 0) & (result.filename.str.contains(label)), \"metric\"] = \"FN\"\n",
    "result.loc[(result.prediction == 0) & (~result.filename.str.contains(label)), \"metric\"] = \"not true\"\n",
    "result.loc[(result.prediction == 1) & (~result.filename.str.contains(label)), \"metric\"] = \"FP\"\n",
    "\n",
    "result.groupby(\"metric\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c9079",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"./models/{label}_final_{classifier_name}.model\"\n",
    "joblib.dump(search_RFE, model_path)\n",
    "\n",
    "print(f\"Model saved successfully at {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
