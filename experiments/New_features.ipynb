{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4157e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import os\n",
    "from skimage.feature import graycomatrix\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from skimage import img_as_ubyte\n",
    "from pillow_heif import register_heif_opener\n",
    "import dlib\n",
    "from scipy.fftpack import fft2, fftshift\n",
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79411c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"../sort/IMG_20231022_152536.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefed572-01ba-422b-bb07-f4da713fa736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(url):\n",
    "    \"\"\"\n",
    "    This function will accept a destination url of an image and return a dictionary of the image properties\n",
    "    :param url: str\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "\n",
    "    res = {}\n",
    "    if url.split(\".\")[-1].lower() == \"heic\":\n",
    "        img = read_heic_image(url)\n",
    "    else:\n",
    "        img = cv2.imread(url)\n",
    "    res['filesize'] = os.path.getsize(url)\n",
    "\n",
    "    size = img.shape\n",
    "    res['size_w'], res['size_h'] = size[0], size[1]\n",
    "    res['aspect_ratio'] = res['size_h'] / res['size_w']\n",
    "    \n",
    "    #Resize image\n",
    "    img = resize_image(img)\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    res['mean_value_b'], res['mean_value_g'], res['mean_value_r'] = np.mean(img, axis=(0, 1))\n",
    "    res['median_value_b'], res['median_value_g'], res['median_value_r'] = np.median(img, axis=(0, 1))\n",
    "    res['std_deviation_b'], res['std_deviation_g'], res['std_deviation_r'] = np.std(img, axis=(0, 1))\n",
    "    res[\"contrast\"], res[\"brightness\"] = calculate_contrast_brightness(gray_image)\n",
    "    res.update(extract_color_histogram(img))\n",
    "    features = calculate_hog_features(gray_image)\n",
    "    res[\"hog_features_mean\"] = np.mean(features)\n",
    "    res[\"hog_features_median\"] = np.median(features)\n",
    "    res[\"hog_features_std\"] = np.std(features)\n",
    "    res[\"hog_features_len\"] = len(features)\n",
    "    res['h_mean'], res['h_median'], res['h_std'], res['s_mean'], res['s_median'], \\\n",
    "        res['s_std'], res['v_mean'], res['v_median'], res['v_std'] = extract_color_features(img)\n",
    "    res['n_objects'], res['area'], res['area_mean'], res['area_std'], res['vert'], res['vert_mean'], res['vert_std'],\\\n",
    "        res['color_mean'], res['color_std'] = extract_shape_and_size_features(img)\n",
    "    res['corners'], res['lines'] = count_corners_and_lines(gray_image)\n",
    "    res.update(detect_faces_opencv(img))\n",
    "    res['has_text'] = has_text_opencv(gray_image)\n",
    "\n",
    "    res.update(calculate_sharpness(gray_image))\n",
    "    res[\"gaussian_blur\"] = estimate_blur_gaussian(gray_image)\n",
    "    res['gibson_blur'] = estimate_blur_gibson(gray_image)\n",
    "    res['gradient'] = calculate_gradients(gray_image)\n",
    "    res.update(calculate_texture_features(gray_image))\n",
    "    res[\"color_balance\"] = np.mean([res['std_deviation_b'], res['std_deviation_g'], res['std_deviation_r']])\n",
    "    res[\"focus_score\"] = calculate_focus(gray_image)\n",
    "    res.update(calculate_image_hashes(url))\n",
    "    del img\n",
    "    del gray_image\n",
    "    return res\n",
    "\n",
    "def calculate_contrast_brightness(gray_image):\n",
    "    contrast = np.std(gray_image)\n",
    "    brightness = np.mean(gray_image)\n",
    "\n",
    "    return contrast, brightness\n",
    "\n",
    "def calculate_hog_features(gray_image):\n",
    "    # Вычисление HOG-признаков\n",
    "    features, _ = hog(gray_image, orientations=8, pixels_per_cell=(8, 8),\n",
    "                              cells_per_block=(1, 1), visualize=True)\n",
    "    # Нормализация HOG-признаков для лучшей интерпретации\n",
    "    features = exposure.rescale_intensity(features, in_range=(0, 10))\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_color_features(image):\n",
    "    # Преобразование изображения в цветовое пространство HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Разделение каналов цветности\n",
    "    h_channel, s_channel, v_channel = cv2.split(hsv_image)\n",
    "\n",
    "    # Пример: вычисление среднего, медианы и стандартного отклонения для каждого канала\n",
    "    h_mean = np.mean(h_channel)\n",
    "    h_median = np.median(h_channel)\n",
    "    h_std = np.std(h_channel)\n",
    "\n",
    "    s_mean = np.mean(s_channel)\n",
    "    s_median = np.median(s_channel)\n",
    "    s_std = np.std(s_channel)\n",
    "\n",
    "    v_mean = np.mean(v_channel)\n",
    "    v_median = np.median(v_channel)\n",
    "    v_std = np.std(v_channel)\n",
    "    del hsv_image, h_channel, s_channel, v_channel\n",
    "    # Возвращение извлеченных признаков\n",
    "    return h_mean, h_median, h_std, s_mean, s_median, s_std, v_mean, v_median, v_std\n",
    "\n",
    "\n",
    "def extract_shape_and_size_features(img):\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Применение пороговой обработки для выделения объектов\n",
    "    _, binary_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Поиск контуров в бинарном изображении\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Количество объектов\n",
    "    n = 0\n",
    "    # Площадь суммарная\n",
    "    area = 0\n",
    "    # Площадь средняя\n",
    "    area_mean = 0\n",
    "    area_list = []\n",
    "    # Количество вершин\n",
    "    vert = 0\n",
    "    vert_list = []\n",
    "    # Среднее количество вершин\n",
    "    vert_mean = 0\n",
    "    vert_list = []\n",
    "    region_features = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Вычисление периметра контура\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "\n",
    "        # Вычисление приближенной формы контура\n",
    "        epsilon = 0.02 * perimeter\n",
    "        approx_shape = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "        # Вычисление площади контура\n",
    "        area_sq = cv2.contourArea(contour)\n",
    "\n",
    "        n += 1\n",
    "\n",
    "        area += area_sq\n",
    "        area_list.append(area_sq)\n",
    "        vert += len(approx_shape)\n",
    "        vert_list.append(len(approx_shape))\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Выделение области на изображении\n",
    "        region = img[y:y + h, x:x + w]\n",
    "\n",
    "        # Вычисление среднего цвета в области\n",
    "        average_color = np.mean(region, axis=(0, 1))\n",
    "\n",
    "        # Добавление характеристик области в список\n",
    "        region_features.append(average_color)\n",
    "\n",
    "    area_mean = np.mean(area_list)\n",
    "    area_std = np.std(area_list)\n",
    "    vert_mean = np.mean(vert_list)\n",
    "    vert_std = np.std(vert_list)\n",
    "    color_mean = np.mean(region_features)\n",
    "    color_std = np.std(region_features)\n",
    "    del gray_image, binary_image, contours, region_features\n",
    "    return n, area, area_mean, area_std, vert, vert_mean, vert_std, color_mean, color_std\n",
    "\n",
    "def count_corners_and_lines(gray_image):\n",
    "    # Детектор углов (Shi-Tomasi)\n",
    "    corners = cv2.goodFeaturesToTrack(gray_image, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
    "    corners_count = len(corners)\n",
    "\n",
    "    # Применение детектора Хафа для обнаружения прямых линий\n",
    "    edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=100)\n",
    "    lines_count = len(lines) if lines is not None else 0\n",
    "    del corners, edges, lines\n",
    "    return corners_count, lines_count\n",
    "\n",
    "def detect_faces_opencv(image):\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "    faces = len(face_locations)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(rgb_image)\n",
    "\n",
    "    blink_count = 0\n",
    "\n",
    "\n",
    "    for landmarks in face_landmarks_list:\n",
    "        left_eye = landmarks['left_eye']\n",
    "        right_eye = landmarks['right_eye']\n",
    "\n",
    "        left_eye_aspect_ratio = eye_aspect_ratio(left_eye)\n",
    "        right_eye_aspect_ratio = eye_aspect_ratio(right_eye)\n",
    "\n",
    "        blink_threshold = 0.25\n",
    "\n",
    "        if abs(left_eye_aspect_ratio) < blink_threshold and abs(right_eye_aspect_ratio) < blink_threshold:\n",
    "            blink_count += 1\n",
    "    del rgb_image, face_locations, face_landmarks_list\n",
    "\n",
    "    return {\"faces\": faces, \"blink\": blink_count}\n",
    "\t\n",
    "def has_text_opencv(gray_image):\n",
    "\n",
    "    _, binary_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    total_area = np.sum([cv2.contourArea(cnt) for cnt in contours])\n",
    "    del binary_image, contours\n",
    "    return total_area\n",
    "\n",
    "def calculate_sharpness(gray_image):\n",
    "    # Вычисление Лапласиана\n",
    "    laplacian = cv2.Laplacian(gray_image, cv2.CV_64F)\n",
    "    blur_metric = laplacian.var()\n",
    "    sharpness = np.mean(laplacian**2)\n",
    "    del laplacian\n",
    "    return {\"sharpness\": sharpness, \"blur_metric\": blur_metric}\n",
    "\n",
    "def calculate_gradients(gray_image):\n",
    "\n",
    "    # Вычисление градиентов по осям X и Y с использованием оператора Собеля\n",
    "    gradient_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gradient_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Вычисление среднеквадратичного значения градиентов (оценка резкости)\n",
    "    sharpness = np.mean(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "    return sharpness\n",
    "\n",
    "def calculate_texture_features(gray_image):\n",
    "    # Преобразование в формат uint8 для использования с GLCM\n",
    "    gray_image = img_as_ubyte(gray_image)\n",
    "\n",
    "    # Вычисление GLCM\n",
    "    glcm = graycomatrix(gray_image, [1], [1], symmetric=True, normed=True)\n",
    "\n",
    "    # Вычисление энергии текстуры\n",
    "    texture_energy = np.sum(glcm**2)\n",
    "    del gray_image, glcm\n",
    "    return {\"texture_energy\": texture_energy}\n",
    "\n",
    "def calculate_focus(gray_image):\n",
    "    # Вычисление градиентов по осям X и Y с использованием оператора Собеля\n",
    "    gradient_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gradient_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    # Вычисление среднеквадратичного значения градиентов (оценка фокусировки)\n",
    "    focus_score = np.mean(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "    return focus_score\n",
    "\n",
    "def calculate_image_hashes(image_path):\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    average_hash = imagehash.average_hash(img)\n",
    "    dhash = imagehash.dhash(img)\n",
    "    phash = imagehash.phash(img)\n",
    "    colorhash = imagehash.colorhash(img)\n",
    "    del img\n",
    "    return {\n",
    "        \"average_hash\": int(str(average_hash), 16),\n",
    "        \"dhash\": int(str(dhash), 16),\n",
    "        \"phash\": int(str(phash), 16),\n",
    "        \"colorhash\": int(str(colorhash), 16)\n",
    "    }\n",
    "\n",
    "def extract_color_histogram(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hist_hue = cv2.calcHist([hsv_image], [0], None, [256], [0, 256])\n",
    "    hist_saturation = cv2.calcHist([hsv_image], [1], None, [256], [0, 256])\n",
    "    hist_value = cv2.calcHist([hsv_image], [2], None, [256], [0, 256])\n",
    "\n",
    "    hist_hue /= np.sum(hist_hue)\n",
    "    hist_hue = np.mean(hist_hue)\n",
    "    hist_saturation /= np.sum(hist_saturation)\n",
    "    hist_saturation = np.median(hist_saturation)\n",
    "    hist_value /= np.sum(hist_value)\n",
    "    hist_value = np.std(hist_value)\n",
    "\n",
    "    del hsv_image\n",
    "\n",
    "    return {\"hue\": hist_hue, \"saturation\": hist_saturation, \"value\": hist_value}\n",
    "\n",
    "def estimate_blur_gaussian(gray_image):\n",
    "    blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    blur_metric = np.sum((gray_image - blurred) ** 2)\n",
    "    return blur_metric\n",
    "\n",
    "def estimate_blur_gibson(gray_image):\n",
    "    f_transform = fftshift(fft2(gray_image))\n",
    "    spectrum = np.abs(f_transform)\n",
    "    blur_metric = np.sum(np.log(1 + spectrum))\n",
    "    return blur_metric\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    vertical_dist = eye[1][1] - eye[5][1]\n",
    "\n",
    "    horizontal_dist = eye[3][0] - eye[0][0]\n",
    "    ear = vertical_dist / horizontal_dist\n",
    "\n",
    "    return ear\n",
    "\n",
    "def read_heic_image(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img = np.array(img)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def resize_image(image, max_dimension=1000):\n",
    "    height, width = image.shape[:2]\n",
    "    if max(height, width) > max_dimension:\n",
    "        scale_factor = max_dimension / max(height, width)\n",
    "        resized_image = cv2.resize(image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "        return resized_image\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7568b073-3bd3-4a1c-b42d-a02e0f08c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = processImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e15612ec-4f2e-4026-8e4d-21b76d77fe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filesize': 9200918, 'size_w': 4624, 'size_h': 3472, 'aspect_ratio': 0.7508650519031141, 'mean_value_b': 95.96919973368841, 'mean_value_g': 101.80926231691079, 'mean_value_r': 96.3584913448735, 'median_value_b': 83.0, 'median_value_g': 98.0, 'median_value_r': 98.0, 'std_deviation_b': 66.76575464080389, 'std_deviation_g': 53.18895813610897, 'std_deviation_r': 51.6642684108485, 'contrast': 52.90612267460573, 'brightness': 99.51564580559254, 'hue': 0.00390625, 'saturation': 0.0023209054, 'value': 0.0038047587, 'hog_features_mean': 0.03421505984734352, 'hog_features_median': 0.036467900407311585, 'hog_features_std': 0.008906721010958345, 'hog_features_len': 93000, 'h_mean': 67.01494540612516, 'h_median': 60.0, 'h_std': 40.58103793010191, 's_mean': 86.47120905459387, 's_median': 80.0, 's_std': 42.36817137956479, 'v_mean': 115.54487616511318, 'v_median': 114.0, 'v_std': 62.655445145410035, 'n_objects': 10411, 'area': 192411.5, 'area_mean': 18.48155796753434, 'area_std': 900.8216878384427, 'vert': 34849, 'vert_mean': 3.3473249447699547, 'vert_std': 3.464324443210473, 'color_mean': 135.52722419995996, 'color_std': 23.85630810595923, 'corners': 100, 'lines': 30408, 'faces': 0, 'blink': 0, 'has_text': 418213.0, 'sharpness': 7360.730111850866, 'blur_metric': 7360.730111418176, 'gaussian_blur': 52626002, 'gibson_blur': 7244674.799693156, 'gradient': 23596.035821571237, 'texture_energy': 0.00010886573015012565, 'color_balance': 57.20632706258712, 'focus_score': 23596.035821571237, 'average_hash': 18446496696528998175, 'dhash': 4794564622338211839, 'phash': 11592762314463055756, 'colorhash': 774201409536}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa44a4a-2886-4d80-8194-c6321fbb1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa5f34f1-6abf-4db0-a225-00c37453723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.04023010413843\n"
     ]
    }
   ],
   "source": [
    "print(test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8cd9124-0dcb-4863-a2e1-93f2b6e8e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_b = 95.96919973368841\n",
    "mean_value_g = 101.80926231691079\n",
    "mean_value_r = 96.3584913448735\n",
    "m = (mean_value_b + mean_value_g + mean_value_r)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b2afa57-df3e-453e-a31c-6717594452cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.04565113182423\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a6a644d-148a-4023-ad9b-432841dc08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_popular_and_rare_pixels(image):\n",
    "    result = []\n",
    "    \n",
    "    # Получаем размеры изображения и количество каналов\n",
    "    height, width, channels = image.shape\n",
    "    \n",
    "    # Проходимся по каждому каналу\n",
    "    for channel in range(channels):\n",
    "        # Получаем уникальные значения пикселей и их количество\n",
    "        unique_values, counts = np.unique(image[:, :, channel], return_counts=True)\n",
    "        \n",
    "        # Находим индекс самого популярного и самого редкого пикселя\n",
    "        popular_index = np.argmax(counts)\n",
    "        rare_index = np.argmin(counts)\n",
    "        \n",
    "        # Получаем значения популярного и редкого пикселей и их количество\n",
    "        popular_pixel = unique_values[popular_index]\n",
    "        rare_pixel = unique_values[rare_index]\n",
    "        popular_count = counts[popular_index]\n",
    "        rare_count = counts[rare_index]\n",
    "        \n",
    "        # Записываем результаты для текущего канала в виде кортежа\n",
    "        result.append((popular_pixel, popular_count, rare_pixel, rare_count))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1592558-6a6c-4a17-aa21-e5f1448bd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = calculate_popular_and_rare_pixels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0804a69a-7641-4008-b2e9-5b2677c7f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(255, 1026831, 245, 2391),\n",
       " (255, 203589, 237, 15983),\n",
       " (255, 309537, 250, 10224)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42433c67-421d-45fb-ac5f-81d41542a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.44 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l = calculate_popular_and_rare_pixels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a48804f-46c1-450a-9517-0deebff4c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "q,w,e,r = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7358712c-6fe2-4afa-b567-8adc34fd7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bc71512-6ab7-4715-96c8-829d33f14c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_name = [\"b\", \"g\", \"r\"]\n",
    "i = 0\n",
    "for ch in l:\n",
    "    res[\"pop_\"+c_name[i]], res[\"pop_n_\"+c_name[i]], res[\"unpop_\"+c_name[i]], res[\"unpop_n_\"+c_name[i]] = ch\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64cffd54-8d09-408d-96fa-c4a4ba3849e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pop_b': 255,\n",
       " 'pop_n_b': 1026831,\n",
       " 'unpop_b': 245,\n",
       " 'unpop_n_b': 2391,\n",
       " 'pop_g': 255,\n",
       " 'pop_n_g': 203589,\n",
       " 'unpop_g': 237,\n",
       " 'unpop_n_g': 15983,\n",
       " 'pop_r': 255,\n",
       " 'pop_n_r': 309537,\n",
       " 'unpop_r': 250,\n",
       " 'unpop_n_r': 10224}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588e33b-f63f-41d7-8daa-4e5a58bda31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
